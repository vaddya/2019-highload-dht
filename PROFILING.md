# Profiling

* [Single node profiling](#single-node)
* [Thread-safe single node](#thread-safe-single-node)
* [Asynchronous server](#asynchronous-server)
* [Sharding](#sharding)

## Single node

### `GET /v0/entity`

* При запросе по несуществующему ключу, значительная часть времени 
и ресурсов аллокации тратится на заполнение стектрейса для 
исключения `NoSuchElementException`, генерируемого в методе 
`DAO::get`. Решение -- генерировать кастомное исключение 
`NoSuchEntityException` без заполнения стектрейса. Было 15.89% 
от всего времени выполнения, стало 0.41%; 99.9-й персентиль 
времени ответа уменьшился с 7.06 мс до 2.73 мс.

* При запросе по существующему ключу, время в основном тратится 
на метод `SSTable::keyAt`, в котором выполняется поиск нужного 
ключа в файле на диске. Данная операция использует бинарный поиск 
по отсортированному массиву пар ключ-значение, поэтому для 
увеличения скорости поиска нужно хранить дополнительную 
информацию о SSTable. Например, можно использовать Bloom 
filter, чтобы снизить шанс поиска отсутствующего ключа, или
хранить дополнительную информацию о блоках ключей в файле,
позволяя быстро найти блок, в котором может находится искомый ключ.

* Большую часть аллокаций занимает создание объектов
`java.nio.DirectByteBufferR` в том же методе `SSTable::keyAt`.
Методы `ByteBuffer::duplicate` и `ByteBuffer::slice` используются 
для создания ключей, чтобы затем сравнить их друг с другом в 
бинарном поиске.

* Примерно одинаковое время занимает поиск по ключу в `DAO` и 
запись HTTP-ответа в сокет. При записи происходит вызов нативного 
блокирующего метода `write`. Таким образом, один поток и производит 
поиск по базе данных, и занимается обработкой HTTP-запроса (чтение
параметров запроса, запись ответа и т.д.). Разумным решением было 
бы использовать для этих задач различные потоки (пулы потоков),
что позволит одному потоку обрабатывать большее число запросов. 

### `PUT /v0/entity`

* Больше половины времени выполнения `DAO::upsert` тратится на
периодический сброс MemTable на диск, тем самым замедляя такие
запросы на несколько порядков. Сброс на диск предполагает работу
с вводом-выводом, включая блокирующий вызов `write`. Из-за этого 
90-й перцентиль (при 600 тыс. запросов на вставку через `wrk`) 
оказался равен 4 мс, в то время как 99-й перцентиль составил более 
1 с (увеличение на 3 порядка!). Логичным решением будет разделение 
задач вставки новой записи в MemTable и сброса MemTable на диск.
Для этого можно при достижении предельного размера MemTable 
переключаться на новый экземпляр MemTable, при этом асинхронно 
отправив заполненную таблицу на сохранение.

* При обычной вставки в MemTable все время тратится на поиск 
позиции для вставки в `java.util.TreeMap`.

* Значительная часть аллокаций происходит при работе с `ByteBuffer` 
во время сброса MemTable на диск. Дополнительные аллокации 
происходят для создания read-only буферов, которые будут храниться
в MemTable. В данном случае, от их создания можно отказаться,
если потребовать, чтобы передаваемые в `DAO::upsert` буферы,
содержащие ключ и значение, были неизменны. Однако, это потребует 
изменения существующего API `DAO`.

* Аналогично GET-запросам, больше половины времени тратится на 
запись ответа в сокет.

### `DELETE /v0/entity`

* В LSM-based хранилищах операции вставки и удаления практически
не отличаются (удаление -- вставка ключа со специальной пометкой
вместо значения), поэтому все сказанное про `PUT`, применимо и 
к `DELETE`.

## Thread-safe single node

### `GET /v0/entity`

* Большую часть времени занимает работа с итераторами в методах 
`IteratorUtils::collectIterators` и `IteratorUtils::mergeIterators`.

* На данный момент не реализован фоновый compaction-поток, из-за 
чего сложность и время поиска по ключу увеличивается с увеличением
числа таблиц на диске.

* Большую часть аллокаций по-прежнему занимает создание объектов 
`java.nio.DirectByteBufferR`.

* При профилировании на блокировки, не была захвачена ни одна
трасса выполнения. Это связано с использованием `ReadWriteLock`,
который позволяет нескольким читателям не блокироваться и 
выполнять поиск параллельно.

### `PUT/DELETE /v0/entity`

* Из flame graph видно, что сбросом MemTable на диск теперь
занимаются выделенные потоки в Executor, что позволяет уменьшить 
99-й перцентиль до 3 мс (вместо 1 с на предыдущем этапе).

* Все еще значительную часть времени (3/4) от обработки запроса 
занимает запись ответа в сокет. 

* Время обработки вставки складывается из создания/копирования
буферов и вставки в потокобезопасную `ConcurrentSkipListMap`.

* При вставке аллокации происходят только при создании `ByteBuffer`
и `TableEntry` для хранения значений в MemTable. В flush-потоках 
аллоцируются `ByteBuffer`, в которые в определенном формате 
укладывается MemTable и сбрасывается на диск.

* При профилировании на lock был замечен только метод 
`TimeUtils::currentTimeNanos`, в котором используется синхронизация
для эмуляции определения времени с точностью до наносекунд.
Очевидно, что в программе используются и другие блокировки, но
т.к. даже при уменьшении интервала профилирования до 100 мкс
других путей не было обнаружено, значит потоки не держат
блокировки по долгу: под блокировкой делается только минимальная 
необходимая работа.

## Asynchronous server

* За счет разделения потоков на пулы селекторов и воркеров удалось 
разбить работу с сокетом (открытие, чтение, запись) и операции 
над хранилищем. Это позволяет независимо масштабировать ресурсы 
(потоки) для этих задач и уменьшить время работы методов сервера,
которые не используют хранилище. 

* При смешанной нагрузке видно, что запрос к `/v0/status` 
отрабатывает примерно в два раза быстрее, чем обращения к 
хранилищу, таким образом долгие обращения к базе не тормозят
другие запросы.

* Запросы на чтение работают на 30-40% дольше, чем запросы на 
вставку (не столь значительная разница может объясняться 
использованием SSD).

### `GET /v0/entity`

* Селекторы заняты только опросом сокетов, разбором запроса и
постановкой задач в очередь. Воркеры заняты получением задачи 
из этой очереди, поиском в хранилище (большая часть работы) и 
записью ответа в сокет. Совсем избавить воркеров от работы с 
сокетом не удалось.

* Большую часть аллокаций производят воркеры при поиске по ключу
(создание буферов с ключами для сравнения) и селекторы при 
разборе запроса.

* Селекторы и воркеры используют синхронизированные методы
класса `Session` для чтения/записи ответа из/в сокет.

### `PUT/DELETE /v0/entity`

* На запись ответа воркер тратит больше времени, чем на вставку
в MemTable.

* Большую часть аллокаций производят селекторы во время разбора
запроса.

* Воркеры активно используют блокировку для синхронизации доступа
к MemTable и определения времени в `TimeUtils::currentTimeNanos`.

### `GET /v0/entities`

* При профилировании используются запросы вида 
`/v0/entities?start=keyN&end=keyM`, где N in 1..8, M = N + 1. При таких
запросах сервер отдавал клиенту около 10К пар ключ-значение.

* Сервер потянул только 100 RPS из-за большого тела ответа
(5410 requests in 1.00m, 0.91GB read).

* Не используем воркеров, потому что создание итератора это
быстрая операция относительно записи ответа в сокет, и большее
количество ресурсов было бы потрачено на синхронизацию селекторов
и воркеров.

* Примерно 1/8 времени обработки запроса тратится на запрос
следующего значения у итератора. Можно попробовать заранее
(спекулятивно) запрашивать следующие значения.

* Происходит большое количество аллокаций памяти для получения
следующего элемента итератора, однако, можно предположить, что
такие объекты не покинут Эдем и будут быстро собраны GC. 

* Блокировки на флейм граф не попали, потому что используются
`ReadWriteLock`, позволяющие работать нескольким читателям 
параллельно. 

## Sharding

### `GET/PUT/DELETE /v0/entity`

* При профилировании ноды, на которую идут все запросы, видно,
что теперь часть времени тратится на проксирования запроса
к соседней ноде: отправка запроса, получение ответа, запись ответа
(два дополнительных стека вызовов TCP по сравнению с single-node).
При этом проксирование происходит в воркерах, что позволяет 
оставить в селекторах только разбор запроса и поставноку задач
в очередь воркерам.

* Дополнительный overhead добавило определение primary нод для
ключей: хеширование ключа, поиск нужной ноды в кольце (Consistent
Hashing).

* Нода, к которой только проксировались запросы, не пыталась
проксировать запрос другой ноде, значит определение ноды по ключу 
на всех нодах было одинаковым и работает верно.

* При смешанной нагрузке (`PUT` на одну из нод кластера, `GET` на 
другую) 99-ые перцентили оказались примерно одинаковые (6.43 мс и 
6.64 мс соответственно). Без SSD получение по ключу, скорее всего,
работало бы значительно дольше (из-за обращения к HDD диску).

* 99.9-ый перцентиль `PUT`-запросов, по сравнению с single-node версией, 
увеличился с 2.61 мс до 5.77 мс. 99.9-ый перцентиль `GET`-запросов 
увеличился с 1.78 мс до 4.05 мс. Однако достигнута главная цель -- 
общая емкость кластера растет пропорционально числу нод в кластере.
Следовательно, наше хранилище горизонтально масштабируется.
